{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPUvsTPU.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pure-water/462deferred/blob/master/GPUvsTPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QueVjeESsyKe"
      },
      "cell_type": "markdown",
      "source": [
        "# Why TPUs ?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    # Define the PV and Q matrices as provided\n",
        "    PV = np.array([\n",
        "        [0.839099,  0.000000, -0.000604, -0.000091],\n",
        "        [-0.000238, 0.771070, -0.330967, -0.126752],\n",
        "        [-0.000688, -0.410530, -0.956432,  1.249704],\n",
        "        [-0.000661, -0.394431, -0.918925,  1.592853]\n",
        "    ])\n",
        "\n",
        "    Q = np.array([\n",
        "        [12.755102, 0.000000, 0.000000, 0.000000],\n",
        "        [0.000000, 12.755102, 0.000000, 0.000000],\n",
        "        [0.000000, 0.000000, 12.755102, 0.000000],\n",
        "        [0.000000, 0.000000, 0.000000, -1.000000]\n",
        "    ])\n",
        "\n",
        "    print(\"PV:\")\n",
        "    print(PV, \"\\n\")\n",
        "\n",
        "    # Compute the inverse of PV\n",
        "    PV_inv = np.linalg.inv(PV)\n",
        "    print(\"PV_inv:\")\n",
        "    print(PV_inv, \"\\n\")\n",
        "\n",
        "    # Check that PV_inv * PV is the identity matrix (or close enough)\n",
        "    identity_approx = np.dot(PV_inv, PV)\n",
        "    print(\"PV_inv * PV (should be identity):\")\n",
        "    print(identity_approx, \"\\n\")\n",
        "\n",
        "    # Compute the transpose of PV_inv\n",
        "    PV_inv_T = PV_inv.T\n",
        "\n",
        "    # Compute QEP: QEP = (PV_inv)^T * Q * (PV_inv)\n",
        "    QEP = PV_inv_T @ Q @ PV_inv\n",
        "    print(\"QEP (Projected Quadratic Error Matrix):\")\n",
        "    print(QEP, \"\\n\")\n",
        "\n",
        "    # Cross validation:\n",
        "    # Recover Q by transforming back: Q_recon = (PV)^T * QEP * PV\n",
        "    Q_recon = PV.T @ QEP @ PV\n",
        "    print(\"Reconstructed Q (should match original Q):\")\n",
        "    print(Q_recon, \"\\n\")\n",
        "\n",
        "    # Check how close the reconstruction is to the original Q\n",
        "    if np.allclose(Q, Q_recon, atol=1e-6):\n",
        "        print(\"Cross validation successful: Reconstructed Q is close to the original Q.\")\n",
        "    else:\n",
        "        diff = np.abs(Q - Q_recon)\n",
        "        print(\"Cross validation failed: Maximum difference =\", np.max(diff))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vypj9reHCrLl",
        "outputId": "d40f2ad2-7d74-4ddc-b2cb-4c35c6fd76e3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PV:\n",
            "[[ 8.390990e-01  0.000000e+00 -6.040000e-04 -9.100000e-05]\n",
            " [-2.380000e-04  7.710700e-01 -3.309670e-01 -1.267520e-01]\n",
            " [-6.880000e-04 -4.105300e-01 -9.564320e-01  1.249704e+00]\n",
            " [-6.610000e-04 -3.944310e-01 -9.189250e-01  1.592853e+00]] \n",
            "\n",
            "PV_inv:\n",
            "[[ 1.19175387e+00 -3.38361268e-04 -2.74197102e-03  2.19242691e-03]\n",
            " [-1.38309426e-07  1.09513314e+00 -1.87935053e+00  1.56162696e+00]\n",
            " [-8.57295370e-04 -4.70063976e-01 -3.44012420e+00  2.66161117e+00]\n",
            " [-5.98878021e-08  4.37817601e-07 -2.45000138e+00  2.55000090e+00]] \n",
            "\n",
            "PV_inv * PV (should be identity):\n",
            "[[ 1.00000000e+00  6.38937659e-20  5.20507609e-19 -1.04672248e-18]\n",
            " [ 2.22000659e-19  1.00000000e+00  1.36311600e-16 -4.43943858e-16]\n",
            " [ 5.69352994e-19  5.69952542e-17  1.00000000e+00 -1.02536479e-15]\n",
            " [ 1.76631954e-19  4.13258087e-17  1.95374835e-16  1.00000000e+00]] \n",
            "\n",
            "QEP (Projected Quadratic Error Matrix):\n",
            "[[ 1.81157911e+01 -5.24423609e-06 -4.05999492e-03  4.21992742e-03]\n",
            " [-5.24423609e-06  1.81157761e+01 -5.62575992e+00  5.85537089e+00]\n",
            " [-4.05999492e-03 -5.62575992e+00  1.89997753e+02 -1.47976007e+02]\n",
            " [ 4.21992742e-03  5.85537089e+00 -1.47976007e+02  1.14962516e+02]] \n",
            "\n",
            "Reconstructed Q (should match original Q):\n",
            "[[ 1.27551020e+01  7.22419907e-18  2.01449527e-17 -2.25351156e-17]\n",
            " [-9.20662959e-19  1.27551020e+01  2.33533383e-15 -2.11788112e-15]\n",
            " [ 2.27538666e-17  1.16259545e-14  1.27551020e+01 -4.99029048e-14]\n",
            " [-2.46016634e-17 -1.72552126e-14 -3.87108878e-14 -1.00000000e+00]] \n",
            "\n",
            "Cross validation successful: Reconstructed Q is close to the original Q.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    # Define the PV and Q matrices as provided.\n",
        "    PV = np.array([\n",
        "        [0.839099,  0.000000, -0.000604, -0.000091],\n",
        "        [-0.000238, 0.771070, -0.330967, -0.126752],\n",
        "        [-0.000688, -0.410530, -0.956432,  1.249704],\n",
        "        [-0.000661, -0.394431, -0.918925,  1.592853]\n",
        "    ])\n",
        "\n",
        "    Q = np.array([\n",
        "        [12.755102, 0.000000, 0.000000, 0.000000],\n",
        "        [0.000000, 12.755102, 0.000000, 0.000000],\n",
        "        [0.000000, 0.000000, 12.755102, 0.000000],\n",
        "        [0.000000, 0.000000, 0.000000, -1.000000]\n",
        "    ])\n",
        "\n",
        "    print(\"PV:\")\n",
        "    print(PV, \"\\n\")\n",
        "\n",
        "    print(\"Q:\")\n",
        "    print(Q, \"\\n\")\n",
        "\n",
        "    # Compute the inverse of PV.\n",
        "    try:\n",
        "        PV_inv = np.linalg.inv(PV)\n",
        "    except np.linalg.LinAlgError:\n",
        "        print(\"PV is not invertible.\")\n",
        "        return\n",
        "\n",
        "    # Verify that PV_inv * PV is approximately the identity matrix.\n",
        "    identity_approx = PV_inv @ PV\n",
        "    print(\"PV_inv * PV (should be identity):\")\n",
        "    print(identity_approx, \"\\n\")\n",
        "\n",
        "    # Compute QEP using the formula: QEP = (PV_inv)^T * Q * (PV_inv)\n",
        "    QEP_python = PV_inv.T @ Q @ PV_inv\n",
        "    print(\"QEP computed in Python:\")\n",
        "    print(QEP_python, \"\\n\")\n",
        "\n",
        "    # Plug in your pre-calculated QEP values.\n",
        "    # These values were provided in your post:\n",
        "    # discriminant: -1312.725220\n",
        "    # Conic Type: Ellipse\n",
        "    # QEP:\n",
        "    # [[18.115772, -0.000000, -0.004019, 0.004183],\n",
        "    #  [-0.000000, 18.115778, -5.625710, 5.855333],\n",
        "    #  [-0.004019, -5.625712, 189.997421, -147.975769],\n",
        "    #  [0.004183, 5.855332, -147.975754, 114.962334]]\n",
        "    my_calculated_QEP = np.array([\n",
        "        [18.115772, -0.000000, -0.004019,  0.004183],\n",
        "        [-0.000000, 18.115778, -5.625710,  5.855333],\n",
        "        [-0.004019, -5.625712, 189.997421, -147.975769],\n",
        "        [ 0.004183,  5.855332, -147.975754, 114.962334]\n",
        "    ])\n",
        "\n",
        "    print(\"Your pre-calculated QEP:\")\n",
        "    print(my_calculated_QEP, \"\\n\")\n",
        "\n",
        "    # Compare the two QEP matrices element-by-element.\n",
        "    if np.allclose(QEP_python, my_calculated_QEP, atol=1e-6):\n",
        "        print(\"The Python computed QEP matches your calculated QEP within the tolerance.\")\n",
        "    else:\n",
        "        diff = QEP_python - my_calculated_QEP\n",
        "        print(\"The Python computed QEP does NOT match your calculated QEP.\")\n",
        "        print(\"Difference matrix:\")\n",
        "        print(diff)\n",
        "        max_diff = np.max(np.abs(diff))\n",
        "        print(f\"Maximum absolute difference: {max_diff}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seIZNlUDD7BM",
        "outputId": "1d0f54df-2ffd-445a-cc60-0cb0ec016498"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PV:\n",
            "[[ 8.390990e-01  0.000000e+00 -6.040000e-04 -9.100000e-05]\n",
            " [-2.380000e-04  7.710700e-01 -3.309670e-01 -1.267520e-01]\n",
            " [-6.880000e-04 -4.105300e-01 -9.564320e-01  1.249704e+00]\n",
            " [-6.610000e-04 -3.944310e-01 -9.189250e-01  1.592853e+00]] \n",
            "\n",
            "Q:\n",
            "[[12.755102  0.        0.        0.      ]\n",
            " [ 0.       12.755102  0.        0.      ]\n",
            " [ 0.        0.       12.755102  0.      ]\n",
            " [ 0.        0.        0.       -1.      ]] \n",
            "\n",
            "PV_inv * PV (should be identity):\n",
            "[[ 1.00000000e+00  6.38937659e-20  5.20507609e-19 -1.04672248e-18]\n",
            " [ 2.22000659e-19  1.00000000e+00  1.36311600e-16 -4.43943858e-16]\n",
            " [ 5.69352994e-19  5.69952542e-17  1.00000000e+00 -1.02536479e-15]\n",
            " [ 1.76631954e-19  4.13258087e-17  1.95374835e-16  1.00000000e+00]] \n",
            "\n",
            "QEP computed in Python:\n",
            "[[ 1.81157911e+01 -5.24423609e-06 -4.05999492e-03  4.21992742e-03]\n",
            " [-5.24423609e-06  1.81157761e+01 -5.62575992e+00  5.85537089e+00]\n",
            " [-4.05999492e-03 -5.62575992e+00  1.89997753e+02 -1.47976007e+02]\n",
            " [ 4.21992742e-03  5.85537089e+00 -1.47976007e+02  1.14962516e+02]] \n",
            "\n",
            "Your pre-calculated QEP:\n",
            "[[ 1.81157720e+01 -0.00000000e+00 -4.01900000e-03  4.18300000e-03]\n",
            " [-0.00000000e+00  1.81157780e+01 -5.62571000e+00  5.85533300e+00]\n",
            " [-4.01900000e-03 -5.62571200e+00  1.89997421e+02 -1.47975769e+02]\n",
            " [ 4.18300000e-03  5.85533200e+00 -1.47975754e+02  1.14962334e+02]] \n",
            "\n",
            "The Python computed QEP does NOT match your calculated QEP.\n",
            "Difference matrix:\n",
            "[[ 1.90929389e-05 -5.24423609e-06 -4.09949213e-05  3.69274214e-05]\n",
            " [-5.24423609e-06 -1.87805414e-06 -4.99218241e-05  3.78936464e-05]\n",
            " [-4.09949213e-05 -4.79218241e-05  3.32026989e-04 -2.38365313e-04]\n",
            " [ 3.69274214e-05  3.88936464e-05 -2.53365314e-04  1.81540441e-04]]\n",
            "Maximum absolute difference: 0.0003320269887012728\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5moeHHv4shGw"
      },
      "cell_type": "markdown",
      "source": [
        "TPUs are tensor processing units developed by Google to  accelerate operations on a Tensorflow Graph. Each TPU packs up to 180 teraflops of floating-point performance and 64 GB of high-bandwidth memory onto a single board. Here is a comparions between TPUs and Nvidia GPUs. The y axis represents # images per seconds and the x axis is different models.\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/800/1*tVHGjJHJrhKaKECT3Z4CIw.png\" alt=\"Drawing\" style=\"width: 150px;\"/>"
      ]
    },
    {
      "metadata": {
        "id": "_SXoMcRs8aRs"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiement\n",
        "\n",
        "TPUs were only available on Google cloud but now they are available for free in Colab. We will be comparing TPU vs GPU here on colab using mnist dataset. We will compare the time of each step and epoch against different batch sizes."
      ]
    },
    {
      "metadata": {
        "id": "4ECTupP8warH"
      },
      "cell_type": "markdown",
      "source": [
        "# Downoad MNIST"
      ]
    },
    {
      "metadata": {
        "id": "oX7DOjhUlCLb"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def get_data():\n",
        "\n",
        "  #Load mnist data set\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "  x_train = x_train.astype('float32') / 255\n",
        "  x_test = x_test.astype('float32') / 255\n",
        "\n",
        "  x_train = np.expand_dims(x_train, 3)\n",
        "  x_test = np.expand_dims(x_test, 3)\n",
        "\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_test  = to_categorical(y_test)\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtEJD_s1wdty"
      },
      "cell_type": "markdown",
      "source": [
        "# Basic CNN"
      ]
    },
    {
      "metadata": {
        "id": "IaZZ2OwmwhKQ"
      },
      "cell_type": "markdown",
      "source": [
        "Note that since we need to run the code on TPU we need to do more work. We need to specify the address of the TPU and tell tensorflow to run the model on the TPU cluster"
      ]
    },
    {
      "metadata": {
        "id": "cUYn3VomnQDL"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib.tpu.python.tpu import keras_support\n",
        "\n",
        "def get_model(tpu = False):\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  #add layers to the model\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  #compile the model\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "  #flag to run on tpu\n",
        "  if tpu:\n",
        "    tpu_grpc_url = \"grpc://\"+os.environ[\"COLAB_TPU_ADDR\"]\n",
        "\n",
        "    #connect the TPU cluster using the address\n",
        "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
        "\n",
        "    #run the model on different clusters\n",
        "    strategy = keras_support.TPUDistributionStrategy(tpu_cluster_resolver)\n",
        "\n",
        "    #convert the model to run on tpu\n",
        "    model = tf.contrib.tpu.keras_to_tpu_model(model, strategy=strategy)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cSoBDg4PwylQ"
      },
      "cell_type": "markdown",
      "source": [
        "#GPU vs TPU\n"
      ]
    },
    {
      "metadata": {
        "id": "yluf1xqjsILa"
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = get_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wn9zXSBUw8m1"
      },
      "cell_type": "markdown",
      "source": [
        "Each time you want to run the model on TPU make sure to set the tpu flag and change the enviornment runtime via  Edit> Notebook Setting > Hardware Accelerator > TPU and then click save."
      ]
    },
    {
      "metadata": {
        "id": "4vAM7pBPxVbm"
      },
      "cell_type": "code",
      "source": [
        "#set tpu = True if you want to run the model on TPU\n",
        "model = get_model(tpu = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_m67tWDhnm7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "59645203-25f4-4e4f-87a2-72da5fa1cf48"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=1024,\n",
        "         epochs=10,\n",
        "         validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1639 - acc: 0.9513 - val_loss: 0.0677 - val_acc: 0.9752\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.1345 - acc: 0.9573 - val_loss: 0.0552 - val_acc: 0.9808\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.1189 - acc: 0.9619 - val_loss: 0.0443 - val_acc: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QGof6K46zXfq"
      },
      "cell_type": "markdown",
      "source": [
        "# Benchmarks\n",
        "\n",
        "Note that TPU setup takes some time when compiling the model and distributing the data in the clusters, so the first epoch will take alonger time. I only reported the time for the later epochs. I calculated the average time accross different epochs."
      ]
    },
    {
      "metadata": {
        "id": "4cbKs72g00sQ"
      },
      "cell_type": "markdown",
      "source": [
        "### Epoch Time ($s$)"
      ]
    },
    {
      "metadata": {
        "id": "QNh64VMDz1Ks"
      },
      "cell_type": "markdown",
      "source": [
        "$$\\left[\\begin{array}{c|c|c}  \n",
        " \\textbf{Batch Size} & \\textbf{GPU} & \\textbf{TPU} \\\\\n",
        " 256 & 6s & 6s\\\\  \n",
        " 512 & 5s & 3s\\\\\n",
        " 1024 & 4s & 2s\\\\\n",
        "\\end{array}\\right]$$"
      ]
    },
    {
      "metadata": {
        "id": "Q8eMm1GD1Mu5"
      },
      "cell_type": "markdown",
      "source": [
        "### Step Time ($\\mu s$)"
      ]
    },
    {
      "metadata": {
        "id": "q1hElmjr05Ah"
      },
      "cell_type": "markdown",
      "source": [
        "$$\\left[\\begin{array}{c|c|c}  \n",
        " \\textbf{Batch Size} & \\textbf{GPU} & \\textbf{TPU} \\\\\n",
        " 256 & 94 \\mu s & 97 \\mu s\\\\  \n",
        " 512 & 82 \\mu  s& 58 \\mu s \\\\\n",
        " 1024 & 79 \\mu s & 37 \\mu s\\\\\n",
        "\\end{array}\\right]$$"
      ]
    },
    {
      "metadata": {
        "id": "J6eOKfyW38rN"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "\n",
        "\n",
        "*   https://qiita.com/koshian2/items/25a6341c035e8a260a01\n",
        "*   https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a\n",
        "*   https://blog.riseml.com/benchmarking-googles-new-tpuv2-121c03b71384\n",
        "*   https://cloudplatform.googleblog.com/2018/02/Cloud-TPU-machine-learning-accelerators-now-available-in-beta.html\n",
        "\n"
      ]
    }
  ]
}